{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries and settings\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "import random\n",
    "from functools import reduce\n",
    "import spotipy\n",
    "import spotipy.util as util\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from spotipy import oauth2\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, lit, rand, udf, to_json, struct\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    FloatType,\n",
    "    ArrayType,\n",
    ")\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = {\n",
    "    \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,org.neo4j:neo4j-connector-apache-spark_2.12:5.0.2_for_spark_3\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = '6546e0f0348341a88d86457d98b3bc9b'\n",
    "secret = '0a569d6ee8f7442cb2857aa515ee8057'\n",
    "redirect_uri='http://localhost:7777/callback'\n",
    "username = 'vass.zora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the Authorisation is complete, we just need to `sp` to call the APIs\n",
    "scope = 'user-top-read user-read-private playlist-modify-private playlist-modify-public'\n",
    "token = util.prompt_for_user_token(username, scope, client_id=cid, client_secret=secret, redirect_uri=redirect_uri)\n",
    "\n",
    "if token:\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "else:\n",
    "    print(\"Can't get token for\", username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting features for each song\n",
    "def fetch_audio_features(sp, df): #TODO this is ugly too\n",
    "    playlist = df[['track_id','track_name']] \n",
    "    index = 0\n",
    "    audio_features = []\n",
    "    \n",
    "    # Make the API request\n",
    "    while index < playlist.shape[0]:\n",
    "        audio_features += sp.audio_features(playlist.iloc[index:index + 50, 0])\n",
    "        index += 50\n",
    "    \n",
    "    # Create an empty list to feed in different charactieritcs of the tracks\n",
    "    features_list = []\n",
    "    #Create keys-values of empty lists inside nested dictionary for album\n",
    "    for features in audio_features:\n",
    "        features_list.append([features['danceability'],\n",
    "                              features['acousticness'],\n",
    "                              features['energy'], \n",
    "                              features['tempo'],\n",
    "                              features['instrumentalness'], \n",
    "                              features['loudness'],\n",
    "                              features['liveness'],\n",
    "                              features['duration_ms'],\n",
    "                              features['key'],\n",
    "                              features['valence'],\n",
    "                              features['speechiness'],\n",
    "                              features['mode']\n",
    "                             ])\n",
    "    \n",
    "    df_audio_features = pd.DataFrame(features_list, columns=['danceability', 'acousticness', 'energy','tempo', \n",
    "                                                             'instrumentalness', 'loudness', 'liveness','duration_ms', 'key',\n",
    "                                                             'valence', 'speechiness', 'mode'])\n",
    "    \n",
    "    # Create the final df, using the 'track_id' as index for future reference\n",
    "    df_playlist_audio_features = pd.concat([playlist, df_audio_features], axis=1)\n",
    "    df_playlist_audio_features.set_index('track_name', inplace=True, drop=True)\n",
    "    return df_playlist_audio_features\n",
    "\n",
    "\n",
    "# Creating a function to get tracks IDs from a playlist\n",
    "def get_playlist_tracks(username,playlist_id):\n",
    "    results = sp.user_playlist_tracks(username,playlist_id)\n",
    "    tracks = results['items']\n",
    "    while results['next']:\n",
    "        results = sp.next(results)\n",
    "        tracks.extend(results['items'])\n",
    "    return tracks\n",
    "\n",
    "\n",
    "# Creating a function get features of each track from track id #TODO this is ugly\n",
    "def get_track_features(track_id):\n",
    "  meta = sp.track(track_id)\n",
    "  features = sp.audio_features(track_id)\n",
    "\n",
    "  # meta\n",
    "  track_id = track_id\n",
    "  name = meta['name']\n",
    "  album = meta['album']['name']\n",
    "  artist = meta['album']['artists'][0]['name']\n",
    "  release_date = meta['album']['release_date']\n",
    "  length = meta['duration_ms']\n",
    "  popularity = meta['popularity']\n",
    "\n",
    "  # features\n",
    "  acousticness = features[0]['acousticness']\n",
    "  danceability = features[0]['danceability']\n",
    "  energy = features[0]['energy']\n",
    "  instrumentalness = features[0]['instrumentalness']\n",
    "  liveness = features[0]['liveness']\n",
    "  loudness = features[0]['loudness']\n",
    "  speechiness = features[0]['speechiness']\n",
    "  tempo = features[0]['tempo']\n",
    "  time_signature = features[0]['time_signature']\n",
    "\n",
    "  track = [track_id, name, album, artist, release_date, length, popularity, danceability, acousticness, energy, instrumentalness, liveness, loudness, speechiness, tempo, time_signature]\n",
    "  return track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting playlist IDs from each of Spotify's playlists #TODO add to method\n",
    "playlists = sp.user_playlists(username)\n",
    "spotify_playlist_ids = []\n",
    "while playlists:\n",
    "    for i, playlist in enumerate(playlists['items']):\n",
    "        spotify_playlist_ids.append(playlist['uri'][-22:])\n",
    "    if playlists['next']:\n",
    "        playlists = sp.next(playlists)\n",
    "    else:\n",
    "        playlists = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = get_playlist_tracks(username, spotify_playlist_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = []\n",
    "for track in tracks:\n",
    "    audio_features.append(sp.audio_features(track['track']['id'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/31 09:47:45 WARN Utils: Your hostname, HP-Elite830 resolves to a loopback address: 127.0.1.1; using 192.168.1.18 instead (on interface wlp1s0)\n",
      "23/05/31 09:47:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/home/vaszo/.local/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/vaszo/.ivy2/cache\n",
      "The jars for the packages stored in: /home/vaszo/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.neo4j#neo4j-connector-apache-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-165d07cb-ede7-4f92-9e99-58a295385e55;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.4.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.3.2 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.9.1 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.6 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in local-m2-cache\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.12;5.0.2_for_spark_3 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.12_common;5.0.2 in central\n",
      "\tfound org.neo4j.driver#neo4j-java-driver;4.4.11 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound org.apache.xbean#xbean-asm6-shaded;4.10 in central\n",
      "\tfound org.neo4j#neo4j-cypher-dsl;2020.1.4 in central\n",
      "\tfound org.apiguardian#apiguardian-api;1.1.0 in central\n",
      ":: resolution report :: resolve 1631ms :: artifacts dl 64ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.3.2 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.4.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.4.0 from central in [default]\n",
      "\torg.apache.xbean#xbean-asm6-shaded;4.10 from central in [default]\n",
      "\torg.apiguardian#apiguardian-api;1.1.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.12;5.0.2_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.12_common;5.0.2 from central in [default]\n",
      "\torg.neo4j#neo4j-cypher-dsl;2020.1.4 from central in [default]\n",
      "\torg.neo4j.driver#neo4j-java-driver;4.4.11 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.6 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.9.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   18  |   0   |   0   |   0   ||   18  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-165d07cb-ede7-4f92-9e99-58a295385e55\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 18 already retrieved (0kB/30ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/31 09:47:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"Final assignment\")\n",
    "    .config(\"spark.jars.packages\", \",\".join(packages))\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=\"localhost:9092\")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kafka.producer.future.FutureRecordMetadata at 0x7fdad1366080>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "producer.send(\"tracks_topic\", b\"\")\n",
    "producer.send(\"number_of_clusters\", b\"\")\n",
    "producer.send(\"audio_features_topic\", b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.readStream.format(\"kafka\")\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "    .option(\"subscribe\", \"tracks_topic, number_of_clusters, audio_features_topic\")\n",
    "    .option(\"startingOffsets\", \"latest\")\n",
    "    .load()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType()),\n",
    "        StructField(\"name\", StringType()),\n",
    "        StructField(\"artists\", ArrayType(\n",
    "            StructType([\n",
    "                StructField(\"id\", StringType()),\n",
    "                StructField(\"name\", StringType())\n",
    "            ])\n",
    "        )),\n",
    "        StructField(\"duration_ms\", StringType())\n",
    "    ]\n",
    ")       \n",
    "\n",
    "\n",
    "number_of_clusters_schema = StructType(\n",
    "    [\n",
    "        StructField(\"K\", IntegerType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "audio_features_schema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"danceability\", FloatType(), True),\n",
    "        StructField(\"energy\", FloatType(), True),\n",
    "        StructField(\"key\", IntegerType(), True),\n",
    "        StructField(\"loudness\", FloatType(), True),\n",
    "        StructField(\"mode\", IntegerType(), True),\n",
    "        StructField(\"speechiness\", FloatType(), True),\n",
    "        StructField(\"acousticness\", FloatType(), True),\n",
    "        StructField(\"instrumentalness\", FloatType(), True),\n",
    "        StructField(\"liveness\", FloatType(), True),\n",
    "        StructField(\"valence\", FloatType(), True),\n",
    "        StructField(\"tempo\", FloatType(), True),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_stream = (\n",
    "    df.selectExpr(\"CAST(value AS STRING)\")\n",
    "    .filter(\"topic = 'tracks_topic'\")\n",
    "    .select(from_json(\"value\", tracks_schema).alias(\"data\"))\n",
    "    .select(\"data.*\")\n",
    ")\n",
    "\n",
    "number_of_clusters_stream = (\n",
    "    df.selectExpr(\"CAST(value AS STRING)\")\n",
    "    .select(from_json(\"value\", number_of_clusters_schema).alias(\"data\"))\n",
    "    .select(\"data.*\")\n",
    ")\n",
    "\n",
    "audio_features_stream = (\n",
    "    df.selectExpr(\"CAST(value AS STRING)\")\n",
    "    .select(from_json(\"value\", audio_features_schema).alias(\"data\"))\n",
    "    .select(\"data.*\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_query = (\n",
    "    tracks_stream.writeStream.format(\"memory\")\n",
    "    .queryName(\"tracks\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "number_of_clusters_query = (\n",
    "    number_of_clusters_stream.writeStream.format(\"memory\")\n",
    "    .queryName(\"number_of_clusters\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "audio_features_query = (\n",
    "    audio_features_stream.writeStream.format(\"memory\")\n",
    "    .queryName(\"audio_features\")\n",
    "    .start()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks_query.stop()\n",
    "# number_of_clusters_query.stop()\n",
    "# audio_features_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for track in tracks:\n",
    "    producer.send(\"tracks_topic\", json.dumps(track['track']).encode(\"utf-8\"))\n",
    "\n",
    "for audio in audio_features:\n",
    "    producer.send(\"audio_features_topic\", json.dumps(audio).encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_spark = spark.sql(\"select * from tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------------------+-------------------------------------------+-----------+\n",
      "|id                    |name                         |artists                                    |duration_ms|\n",
      "+----------------------+-----------------------------+-------------------------------------------+-----------+\n",
      "|227bXIqHWP8Z7gycUGO1sY|Coax & Botany                |[{6sHCvZe1PHrOAuYlwTLNH4, Gus Dapperton}]  |173742     |\n",
      "|3mJcEwAZ7GgPmppR6LvAdp|Sockboy                      |[{6sHCvZe1PHrOAuYlwTLNH4, Gus Dapperton}]  |247029     |\n",
      "|2CNM0Q27eYpDRo5GTVTNYM|Matador                      |[{1CMml5seBEaxQzlmaGxMPx, The Buttertones}]|199360     |\n",
      "|6X3FZtz4cKU2MKSQlGG9ZG|Bags                         |[{3l0CmX0FuQjFxr8SK7Vqag, Clairo}]         |260519     |\n",
      "|7zI1PDpYJ1yEyAINS604Zs|Humongous                    |[{2D4FOOOtWycb3Aw9nY5n3c, Declan McKenna}] |321680     |\n",
      "|6BqWhxll86CGGE6WxgdRqG|Golden Skans                 |[{2qlAMLpUyBjZgnzuFXXZXI, Klaxons}]        |165120     |\n",
      "|5EpU5EsanKQTfRfIVNOa1M|No Kind Words                |[{0vW8z9pZMGCcRtGPGtyqiB, The Maccabees}]  |219426     |\n",
      "|4eiLC2Bd1olDQ0Ki8risiD|Mixed Signals                |[{1ShwUjKIwQRaUJij7jgRhp, The Night Caf√©}] |206323     |\n",
      "|6KKHXbJtnJPjla3V49YPac|Prune, You Talk Funny        |[{6sHCvZe1PHrOAuYlwTLNH4, Gus Dapperton}]  |212701     |\n",
      "|15fSe0A90WtPu1wHqCCWcB|Home                         |[{0U7iI0Dk4Ojvi17nZboNO4, Vacations}]      |145666     |\n",
      "|5hM5arv9KDbCHS0k9uqwjr|Borderline                   |[{5INjqkS1o8h1imAzPqGZBb, Tame Impala}]    |237800     |\n",
      "|716OZGLBg3vkNfMTpfbYm6|Days                         |[{32zeX1IoVKAGWMyy1isKUq, No Vacation}]    |320328     |\n",
      "|25SJaCCPiosugnlY53VhRG|Freaking Out the Neighborhood|[{3Sz7ZnJQBIHsXLUSo0OQtM, Mac DeMarco}]    |173888     |\n",
      "|6OiRh4kttAs1YWglvTcYkB|Alrighty Aphrodite           |[{6fC2AcsQtd9h4BWELbbire, Peach Pit}]      |207813     |\n",
      "|5wv2XK6ms7KBBVDD1cOwlx|Cool with You                |[{77mJc3M7ZT5oOVM7gNdXim, Her's}]          |375656     |\n",
      "+----------------------+-----------------------------+-------------------------------------------+-----------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tracks_spark.show(15, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_spark = spark.sql(\"select * from audio_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------+------+----+--------+----+-----------+------------+----------------+--------+-------+-------+\n",
      "|id                    |danceability|energy|key |loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|tempo  |\n",
      "+----------------------+------------+------+----+--------+----+-----------+------------+----------------+--------+-------+-------+\n",
      "|227bXIqHWP8Z7gycUGO1sY|null        |null  |null|null    |null|null       |null        |null            |null    |null   |null   |\n",
      "|227bXIqHWP8Z7gycUGO1sY|0.663       |0.623 |11  |-5.283  |1   |0.0239     |0.14        |0.0             |0.0918  |0.773  |81.513 |\n",
      "|3mJcEwAZ7GgPmppR6LvAdp|0.651       |0.719 |6   |-3.38   |0   |0.0334     |0.109       |0.0             |0.129   |0.4    |117.01 |\n",
      "|2CNM0Q27eYpDRo5GTVTNYM|0.462       |0.837 |4   |-4.513  |0   |0.0365     |0.00169     |0.0182          |0.103   |0.582  |146.943|\n",
      "|6X3FZtz4cKU2MKSQlGG9ZG|0.742       |0.546 |1   |-7.694  |1   |0.0315     |0.172       |0.38            |0.115   |0.868  |104.996|\n",
      "|7zI1PDpYJ1yEyAINS604Zs|0.35        |0.806 |9   |-7.356  |0   |0.086      |6.1E-5      |4.36E-4         |0.152   |0.486  |115.068|\n",
      "|6BqWhxll86CGGE6WxgdRqG|0.463       |0.836 |2   |-2.776  |0   |0.0381     |4.18E-4     |7.38E-6         |0.25    |0.713  |141.955|\n",
      "|5EpU5EsanKQTfRfIVNOa1M|0.239       |0.686 |9   |-6.666  |0   |0.0603     |0.0209      |0.107           |0.0713  |0.119  |172.997|\n",
      "|4eiLC2Bd1olDQ0Ki8risiD|0.5         |0.936 |2   |-4.412  |0   |0.0404     |3.17E-4     |0.751           |0.504   |0.882  |161.979|\n",
      "|6KKHXbJtnJPjla3V49YPac|0.57        |0.75  |10  |-7.193  |0   |0.0383     |0.0177      |0.00247         |0.197   |0.578  |140.063|\n",
      "|15fSe0A90WtPu1wHqCCWcB|0.644       |0.672 |9   |-5.438  |0   |0.0246     |0.00562     |6.44E-4         |0.107   |0.412  |89.868 |\n",
      "|5hM5arv9KDbCHS0k9uqwjr|0.621       |0.873 |5   |-3.067  |0   |0.0369     |0.0406      |9.1E-6          |0.0824  |0.873  |97.96  |\n",
      "|716OZGLBg3vkNfMTpfbYm6|0.469       |0.866 |4   |-5.372  |1   |0.0321     |0.0371      |0.921           |0.183   |0.56   |131.0  |\n",
      "|25SJaCCPiosugnlY53VhRG|0.565       |0.832 |8   |-5.751  |0   |0.108      |0.0639      |0.0291          |0.386   |0.847  |143.302|\n",
      "|6OiRh4kttAs1YWglvTcYkB|0.534       |0.724 |6   |-4.675  |0   |0.0495     |0.00605     |0.0929          |0.108   |0.503  |81.846 |\n",
      "+----------------------+------------+------+----+--------+----+-----------+------------+----------------+--------+-------+-------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "audio_features_spark.show(15, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
